\chapter{Theoretical introduction}
\label{chap:Theory}

This chapter introduces the basic concepts that are needed to understand future chapters. It collects definitions and technical background that are referenced throughout the thesis. The aim is to give the reader enough context to follow the overview and analysis of anonymous communication networks (ACNs). The chapter is organised as follows: it starts with the definitions of anonymity and privacy, then describes distributed hash tables and basic concepts from cryptography, and finally presents the network models, blockchain and cryptocurrency foundations, and an overview of protocols that are referenced in later sections. All these elements are important to understand the technical and analytical parts of the thesis.

\section{Anonymity and privacy}
The definition of anonymity used in this thesis is based on a paper titled "A terminology for talking about privacy by data minimization" \cite{anon-terminology}.
According to the paper: "Anonymity of a subject means that the subject is not identifiable within a set of subjects, the anonymity set.". Another important property in anonymous communication systems is unlikability. According to the same paper: "Unlinkability of two or more items of interest (IOIs, e.g., subjects, messages, actions, ...) from an attacker’s perspective means that within the system (comprising these and possibly other items), the attacker cannot sufficiently distinguish whether these IOIs are related or not."
Pseudonymity refers to the use of pseudonyms as identifiers, where a pseudonym is an identifier of a subject other than one of their real names.
Privacy is the right to keep personal matters and relationships secret, as well as the ability to determine when, how, and which information about oneself is revealed.
Anonymity can be considered as a method to achieve privacy.

\subsubsection{Why is anonymity and privacy needed?}

For the same reason that in all well-prosper democratic countries there are anonymous elections. No one should be obliged to reveal information they do not wish to disclose; individuals should have the right to decide to whom and what information they reveal. In recent years, privacy has been increasingly compromised as personal data have become highly valuable to large corporations. Data are sometimes said to be the petroleum of the 21st century, highlighting their significant value in the modern economy.
As with many technologies, anonymity can be used for both positive and negative purposes. Although negative uses often receive more attention in the media, this thesis will primarily focus on beneficial use cases to provide a balanced perspective.
It should be noted that attempts to restrict anonymous networks primarily affect users with legitimate intentions, as malicious actors are often able to circumvent such restrictions and may use alternative solutions that do not require scalability.

Some organisations claim they do not retain the content of communications, but only metadata - such as who communicates with whom, when, where, and how often. NSA General Counsel Stewart Baker said: "metadata absolutely tells you everything about somebody’s life. If you have enough metadata, you don’t really need content." and General Michael Hayden, former NSA director, added: "We kill people based on metadata" \cite{metadata-kill}. Metadata, in fact, should not be neglected when it comes to the privacy topic.
According to the European Data Protection Supervisor, privacy is a fundamental human right and a component of a sustainable democracy \cite{privacy-eu}.

\subsubsection{Anonymity by design and anonymity by policy}
Sometimes service providers, Virtual Private Network (VPN) service providers in particular, advertise their services as anonymous, although in reality they can deanonymise users on demand; they just claim that they would not do it or that they keep logs of their user activity. However, history shows that such assurances are not always reliable and that users cannot be certain that anonymous service providers will not disclose or sell their information \cite{vpns}. This approach is known as anonymity by policy.
On the other hand, anonymity by design makes it impossible for the service provider to reveal the identity of the service users by creating a service or network in such a way. In other words, there is no need to trust any third party other than the code itself, which you can verify in most cases because they are usually open source. Proper privacy can only be achieved with anonymity by design.

\subsubsection{Anonymous communication network}
Anonymous Communication Network is a kind of network that allows anonymous uni- or bi-directional communication. They are usually implemented as overlay networks. An overlay network is a logical network that operates on top of an underlying physical network.

\subsubsection{Clearnet, Deep Web, and Hidden Services}

\textbf{Clearnet} refers to the publicly accessible portion of the Internet. It includes a wide variety of protocols and services, including, but not limited to, the World Wide Web. All resources on the clearnet are accessible without the use of ACNs. The \textbf{surface web} is a subset of the clearnet and denotes the part of the World Wide Web that is indexed by conventional search engines such as Google or Bing. It consists of publicly available web pages that can be accessed without authentication or authorisation.

The \textbf{deep web} refers to the segment of the World Wide Web that is not indexed by standard search engines. This includes resources such as private databases, academic repositories, webmail, and other pages that require authentication, authorisation or are otherwise hidden from public view.

The terms \textbf{darknet} and \textbf{hidden services} refer to a broad range of services and resources that are anonymous themselves, especially in terms of their location, and are accessible exclusively through specialised anonymous communication networks (ACNs). These services are not restricted to the World Wide Web. The \textbf{dark web} or \textbf{hidden web services} specifically describe web-based resources that are only accessible through such networks and not through standard browsers or search engines. Although these concepts are often associated with negative media coverage, it is important to emphasise that such technologies also enable legitimate uses, including privacy protection, secure communication, and the promotion of free expression. For the sake of clarity, the term hidden services will be used throughout this thesis when referring to these resources.

% \section{Client-server and peer-to-peer models}

% \subsubsection{Client-server model}
% The client-server model is currently the most popular computing paradigm. Essentially, it assumes that many clients connect to centralised servers. Today, these servers are typically run in large data centres controlled by major organisations.

% \subsubsection{Peer-to-peer model}
% Peer-to-peer (P2P) computing is a decentralised network architecture where each participant (peer) has equal privileges and can initiate or complete transactions without relying on a centralised server. While it may be surprising, the Internet and its predecessors were not designed to be client-server oriented. In fact, the basic idea of peer-to-peer computing dates back to the Arpanet, the predecessor of the Internet, and the first Request for Comments \cite{rfc1}, which was associated with it. Arpanet was created in the way that it would be resilient to a potential nuclear attack, and therefore it was not centralised.

\section{Distributed Hash Tables}
A Distributed Hash Table (DHT) is a decentralised system for storing key-value pairs, where keys are hashes of fixed length and evenly distributed across a large keyspace, allowing data to be stored across many machines instead of relying on a single central server. This distribution improves reliability, avoids single point failure, and eliminates the need to trust a single entity, with various strategies used to assign keys to specific machines.
One of the first proposed DHTs was Chord \cite{chord}. It organises nodes and keys in a ring using consistent hashing, where each node maintains a set of pointers ("fingers") to efficiently locate keys in $O(log (n))$ hops. Keys are stored at their closest successor node, ensuring even distribution and scalable lookups across the network.
Another popular DHT is Kademlia \cite{kademlia}. It uses an XOR-based distance metric to organise the nodes in keyspace, allowing each node to efficiently locate values near itself by recursively querying the nodes closer to the target, resulting in $O(log (n))$ lookup hops. The nodes keep more detailed information about the nearby nodes, structuring their routing tables as binary trees based on the bitwise distance.

\section{Cryptography basics}
Cryptography is a science of concealing the meaning of a message. This section introduces the basic cryptographic concepts and algorithms that will be referenced throughout the thesis.

\subsubsection{Information security attributes}
Information security, or InfoSec, is a practice of protecting information. Several attributes can be distinguished, slightly varying depending on the definition. From the point of view of this work, the most important will be four of them:
\begin{enumerate}
    \item Confidentiality
    \item Authenticity
    \item Integrity
    \item Non-repudiation
\end{enumerate}
\textbf{Confidentiality} means that only authorised persons can access the data. In cryptographic systems, it is ensured by the possession of the decryption key. \textbf{Authenticity} relates to verifying that the identity of the entity performing a given action is as declared. \textbf{Integrity} ensures that the data have not been modified in an unauthorised way. \textbf{Non-repudiation} guarantees that parties involved in data exchange cannot deny their participation later.

\subsubsection{Symmetric cryptography}
In symmetric cryptography, one shared key is used on both sides of a communication to encrypt and decrypt messages. Symmetric cryptography ensures confidentiality, as (ideally) the key is needed in order to read the content of a message, and the key is only shared between two sides of the communication that are often referred to as Alice and Bob. Symmetric cryptography ciphers can be divided into two subcategories. The first is the \textbf{block ciphers}, where fixed-size blocks are encrypted. In case the data does not fit the block, a padding is used. The second is \textbf{stream ciphers}, where only one bit or byte is encrypted at a time.

\subsubsection{Asymmetric cryptography}
In asymmetric cryptography, or public-key cryptography, each entity uses a pair of keys instead of one shared symmetric key. The private key is a part that, as the name suggests, is specific to the entity exclusively and cannot be revealed to anyone else. However, the public key can be freely distributed. The message encrypted with the public key can only be decrypted with the private key from the same pair. Analogically, the message "encrypted" with the private key can be "decrypted" with the public key, although calling it encryption and decryption does not make much sense, as the public key is freely distributed; therefore, everyone can read the message. The more appropriate terms that are used in this example are signing and verifying, as if a given message can be decrypted with a certain public key, then certainly the one who signed (encrypted) it must be the owner of the private key from the same key pair.
Encryption with asymmetric cryptography is in general much slower than with symmetric one; therefore, it is most often used for different purposes, such as the digital signature, which will be described later.

\subsubsection{Elliptic-curve cryptography (ECC)}
An approach to asymmetric cryptography using elliptic curves over finite fields has gained popularity in recent years, although it is not a new technique, as its origin dates back to 1985. ECC is believed to offer the same level of security as other widely used asymmetric cryptographic methods but with significantly shorter key lengths. One of the popular examples of a curve that can be efficiently used in this kind of cryptography is Curve25519.

\subsubsection{Hash functions}
Hash function algorithms allow for transformation of any input into a fixed-size output, called a hash, in a deterministic way, which means that each time a certain input produces the same output if the same hash function and its parameters are used. Another important feature of hash functions is its one-sidedness, in that the original input cannot be determined based on the produced hash. The hash function should also produce output that is uniformly distributed, and it should be hard to find two inputs that produce the same output - this situation is called a hash collision.

\subsubsection{Digital signature}
One of the most popular use cases of asymmetric cryptography is the digital signature. It is a mathematical scheme for verifying the authenticity, integrity, and non-repudiation of origin for the given message. In a simplified way, it works as given: The sender generates a private/public key pair and distributes the public key. He generates a hash of the message he has written and signs this hash with his private key. The receiver receives the message along with the signed hash. As the hash function is known, he creates a hash of the message himself with it, verifies the signed hash, and compares the two result hashes. If they are equal, then the signature is valid.

\subsubsection{Quantum and post-quantum cryptography}
Quantum cryptography is the science of using quantum mechanics in cryptography. Quantum cryptography algorithms are designed to work specifically on quantum computers.
On the other hand, post-quantum cryptography (PQC) refers to the development of cryptographic algorithms that work on traditional machines but that are resistant to potential attacks that use quantum computers.

\subsubsection{Popular cryptographic algorithms and hash functions}
In the field of cryptography, several algorithms and hash functions are fundamental to the construction of secure systems. The following are the most significant ones relevant to ACNs:
\begin{itemize}
\item AES
\item RSA
\item ElGamal
\item DSA
\item ECDSA
\item EdDSA
\item Diffie-Hellman Key Exchange
\item ECDH
\item SHA
\end{itemize}
\textbf{AES}, or Advanced Encryption Standard, is the most popular block cipher today, considered a safe symmetric cryptography solution, especially with the longest possible 256-bit keys. Due to its popularity, it often has dedicated hardware support.
\textbf{RSA} is one of the first asymmetric cryptography algorithms and still the most popular. The name RSA is an abbreviation from its creators' surnames: Rivest, Shamir, Adleman. Its security relies on the difficulty of the factoring problem, which means factoring the product of two large prime numbers. It can be used for both encryption and digital signature.
\textbf{ElGamal} is the second most popular asymmetric cryptography algorithm after RSA. It is based on the discrete logarithm problem. It supports both encryption and digital signatures.
\textbf{DSA}, or Digital Signature Algorithm, is an asymmetric cryptography algorithm used specifically for digital signatures, not for encryption. It is based on the discrete logarithm problem.
\textbf{ECDSA}, meaning elliptic-curve DSA, is a variant of DSA that uses elliptic-curve cryptography.
\textbf{EdDSA}, meaning Edwards-curve DSA, is a variant of DSA utilising Schnorr signature based on twisted Edwards curves. Although the name might suggest correlation with ECDSA, both are completely different signature schemes. Ed25519 is a specific example of the EdDSA variant and uses the edwards25519 curve, which is related to the popular Montgomery curve Curve25519. 
\textbf{Diffie-Hellman Key Exchange}, or simply Diffie-Hellman (DH), is a key agreement algorithm that two parties can use to agree on a shared secret. The shared secret is converted into keying material, and the keying material is used as a symmetric encryption key. The Diffie-Hellman key exchange uses the properties of modular arithmetics.
\textbf{ECDH} is an elliptic-curve version of the DH key agreement. Usually, Curve25519 is chosen as a curve because it is fast and not proprietary.
\textbf{SHA}, or Secure Hash Algorithms, are a family of hash functions. Currently, there are four versions of SHA. \textbf{SHA-0} refers to the original hash function with 160-bit output that was published under the name SHA. \textbf{SHA-1} is an improved version of SHA-0, still using 160 bits. NSA designed it as part of the DSA algorithm. \textbf{SHA-2} is a family of two hash functions designed by NSA: SHA-256 and SHA-512. The postfix in the name determines the length of the output of the hash function (256 bits or 512 bits). There are also modified and truncated versions of these two standards: SHA-224, SHA-384, SHA-512/224, and SHA-512/256.
\textbf{SHA-3} is the latest hash function of the SHA family, also known as Keccak. Although the hash lengths are the same as in the SHA-2 family, the inner workings of the algorithm are significantly different.

\section{ISO/OSI reference model and TCP/IP suite}
The two most popular networking models used today are ISO/OSI and TCP/IP. They both help us to analyse the end-to-end communication between two parties. They both consist of several layers: ISO/OSI consists of 7, while TCP/IP is of 4. Each of these layers has certain clear goals to fulfill. Each layer has certain protocols and protocol-specific units of information composed of user data and control information called protocol data units (PDUs).

The ISO/OSI model has the following layers:
\begin{enumerate}
\item Physical layer
\item Data link layer
\begin{enumerate}
    \item Media Access Control sublayer
    \item Logical/Data Link Control sublayer
\end{enumerate}
\item Network layer
\item Transport layer
\item Session layer
\item Presentation layer
\item Application layer
\end{enumerate}
\textbf{Physical layer} is the first and lowest layer, responsible for the transmission of unstructured data between a device and a transmission medium. The PDU of the physical layer is a bit.

\textbf{Data link layer} is the second layer, responsible for node-to-node data transfer between two directly connected devices. In this layer, two sublayers can be distinguished; \textbf{Media Access Control}, usually implemented on a hardware, manages access control, encapsulates and decapsulates data, adds header and trailer, while \textbf{Logical/Data Link Control (LLC/DLC)} is responsible for communication with physical and network layers and for flow control. The PDU of the data link layer is a frame.
In real-world examples, technologies designated for the lowest layers usually cover both the physical and data link layer. Examples include Ethernet, the most popular wired local area network (LAN) technology today, or 802.11, sometimes referred to as Wi-Fi, the most popular wireless LAN technology.

\textbf{Network layer} is the third layer, responsible for addressing hosts, ensuring connectionless communication, routing, and relaying messages. It is also the first layer that is "sentient" of the network, which means that there is something outside the current machine or current link. The most popular protocol of this layer is the IP protocol in two versions: IPv4 and IPv6. The PDU of the network layer is a packet.

\textbf{Transport layer} is the fourth layer, responsible for interprocess communication. Its role is to address ports and control connection, flow and errors as well as message multiplexation and demultiplexation. There are two most popular protocols in this layer: TCP, responsible for reliable communication with the cost of delays, and UDP, responsible for unreliable communication, but with smaller delays. The PDU in the transport layer is a segment for TCP and a datagram for UDP.

\textbf{Session layer} is the fifth layer, responsible for maintaining and managing interprocess sessions. The PDU of the session layer is data. 

\textbf{Presentation layer} is the sixth layer, sometimes referred to as the syntax layer, which is responsible for translating, coding, and decoding data between applications. The PDU of the presentation layer is also data.

\textbf{Application layer} is the seventh and last layer in the ISO/OSI model application layer that is responsible for providing an interface for communication between applications. Once again, the PDU of the application layer is data.


For the sake of simplicity, it can be said that in the TCP/IP model there are four layers that correspond to one or more ISO/OSI layers:
\begin{enumerate}
    \item Link layer
    \item Internet layer
    \item Transport layer
    \item Application layer
\end{enumerate}
\textbf{Link layer} is the layer that serves as a combination of the first and second layers of ISO/OSI. \textbf{Internet layer} is the layer that corresponds to the network layer of the ISO / OSI model. \textbf{Transport layer} corresponds to the layer with the same name from the ISO/OSI model. \textbf{Application layer} combines the sessions, presentations and application layers of the ISO / OSI model.

The ISO/OSI was a model created from the ground up in the late 1970s and early 1980s as a framework based on the set of tasks that needs to be fulfilled in order to have reliable communication and each layer in this model was assigned a specific role. One of the most criticised elements of the ISO/OSI model were layers 5 and 6 which were thought to be an exaggeration, as they can be easily integrated with the application layer. That is also why often, when referring to the application layer, the fifth, sixth, and seventh layers are grouped together. Regardless of the criticism, the model is still used as a reference model.

TCP/IP is an evolving model whose origins date back to ARPANET \cite{rfc1}. It has a simpler, more concise, and pragmatic approach compared to the ISO/OSI model, and it has specific protocol solutions. An important difference between ISO/OSI and TCP/IP models is the fact that in the ISO/OSI the communication is only possible between adjacent layers, while in TCP/IP any layer can refer to any other layer, including the same layer. An example can be the IP protocol utilising ICMP and vice versa.

This paper will focus on layers 3-7 from the ISO/OSI model (or layers 2-4 from the TCP/IP model). When referring to the seventh layer from the ISO/OSI model, fifth and sixth will also be included implicitly in the reference for the sake of simplicity.


\section{Blockchain and cryptocurrencies}
Blockchain is a shared, immutable, and distributed ledger that records information in a growing list of entries called blocks. Blocks are chained together using hash functions. Each new block depends on the integrity of the previous blocks in an unaltered stage and therefore the history of a blockchain cannot be altered. Blockchains are often used as the backbones of various cryptocurrencies, digital currencies based on cryptography, where transactions are written as records on the blockchain with an appropriate consensus mechanism.
In today’s world, cash usage is declining as countries shift toward cashless payments. This trend poses a major threat to privacy. Unlike cash transactions, which are private and typically known only to the two parties involved, cashless payments lack this privacy. Every cashless payment is visible to the government, tax authorities, banks, and possibly many more entities. This information can be used against the people who make such transactions. Cryptocurrencies offer a way to restore the privacy of transactions. They allow for private peer-to-peer transactions between users. Additionally, cryptocurrencies have excellent transfer properties, enabling reasonably quick transfers, regardless of the day of the week, if it is a national holiday or not. Unlike traditional bank transfers, cryptocurrency transactions cannot be blocked or restricted by financial institutions or government entities.


\section{Network protocols overview}
This section briefly describes the most important network protocols that are referenced throughout the thesis. These protocols are relevant to understanding the mechanisms behind anonymous communication networks.

\begin{itemize}
    \item IP
    \item TCP
    \item UDP
    \item TLS
    \item SOCKS
    \item BitTorrent
\end{itemize}

\textbf{IP} is the network layer communication protocol in the ISO/OSI model and the Internet layer protocol in the TCP/IP are responsible for connectionless communication, relaying datagrams, and addressing hosts. It is the most popular protocol for this layer. IP is often associated with convergence as it serves as a universal protocol that supports both upper and lower layer protocols. The IP protocol exists in two versions: IPv4 and IPv6. The IPv4 was introduced first and it had some significant flaws, among which the most critical one is the address space - it was not predicted that the Internet would be so huge that 4 billions of potential addresses would not be enough; as is known today, it is definitely not. There are many actions taken to postpone the issues related to the exhaustion problem as much as possible like the introduction of classless addressing, public/private address distinction with NAT mechanism, but the only viable long-term solution is moving on to the newer version of the IP protocol, IPv6. It can have up to $2^{128}$ addresses.

\textbf{TCP} is one of the two most popular transport layer protocols responsible for interprocess connection-based communication. Provides connection, flow, and error control. TCP is used when reliability is more important than potential delays.

\textbf{UDP} is second of the two most popular transport layer protocols responsible for connectionless interprocess communication. It lacks error control and flow control. It does not guarantee the delivery of a datagram or its correct order; however, these mechanisms can be implemented in the higher layers.

\textbf{TLS}, or Transport Layer Security, is a protocol widely used to ensure confidentiality and authentication for client-server applications. The predecessor of the TLS protocol was SSL; therefore, TLS is sometimes still referred to as SSL for historical reasons. 

The \textbf{SOCKS} protocol allows network packets to be exchanged between the client and the server with an intermediary proxy server between. Currently, the latest version of this protocol is SOCKS5.

\textbf{BitTorrent} is a peer-to-peer protocol for file sharing. Its important feature is decentralisation, meaning that there is no possibility to take down one central server as it was for some other peer-to-peer file-sharing solutions like Napster. Users utilise BitTorrent clients, the programs that allow them to share files via BitTorrent. The communication is optionally assisted by the BitTorrent trackers that provide available files and find peer users, known as seeds. The other option, depending on the BitTorrent client implementation, is, for example, a distributed hash table as an alternative for the trackers. In BitTorrent files are divided into pieces and the file that holds a list of these pieces is called Torrent. After downloading a piece, the user starts sharing it with other peers, becoming one of the sources of this piece (seed). Each piece is associated with its hash to provide integrity.

\section{Summary}
This chapter provided the technical background and definitions required in the rest of the thesis. The discussed topics include anonymity and privacy, distributed hash tables, cryptography basics, network models, blockchain and cryptocurrencies, and a short summary of the most important network protocols. By collecting these fundamental concepts in one place, this chapter ensures that the reader has the necessary knowledge for understanding the design and evaluation of anonymous communication networks in the next chapters. Its function is to make the thesis self-contained and to make later technical discussions easier to understand.
